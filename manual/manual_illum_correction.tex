\section{Illumination correction}
\label{sec:IlluminationCorrection}

\subsection{Main script}
\label{subsec:MainScript}
This manual is describing the illumination correction code in THELI in detail in chronological order. All scripts contain detailed information about the required command line arguments and the history of changes. On github, every single change is also covered with a small comment. As far as possible, all steps are using multiprocessing features and are instrument independent (required information are taken from the THELI camera config file).\\
The needed command line arguments for the main script (illum\_correction.sh, written in bash) are (in this order):

\begin{table}[H]
\centering
\begin{tabular}{lp{11.5cm}}
MAIND: & Main directory\\
STANDARDD: & Directory to files used for zeropoint calculation / illumination correction from main directory\\
FILTERNAME: & Used filtername, e.g. r\_SDSS\\
SOLUTION: & In \textrm{THELI} three different fits for zeropoint estimation are available (the number in brackets corresponds to the given argument):\\
 & \textbf{(1)} 3 parameter fit (zeropoint, extinction and color).\\
 & \textbf{(2)} 2 parameter fit (zeropoint and color, extinction fixed to -0.10mag).\\
 & \textbf{(3)} 1 parameter fit (only zeropoint, extinction fixed to -0.10mag, color fixed to 0.05mag).\\
EXTENSION: & In \textrm{THELI} all files have an extension depending on reduction steps. This is needed to find all files.\\
FILTER: & Used filter in reference catalog, e.g. r.\\
MODE: & Depending on the zeropoint calibration, an illumination correction can be done by using all data from one run ("RUNCLAIB") or each night individually ("NIGHTCALIB").\\
COLOR: & Used color index, e.g. gmr for $g-r$.
\end{tabular}
\caption{List of command line arguments for main script}
\label{tab:CommandLineArgumentsMainScript}
\end{table}

\textbf{Example:} \verbatim{./illum\_correction.sh /data/KIDS\_V0.5/run_1/ STANDARD\_r\_SDSS r\_SDSS 2 OFCS r RUNCALIB}

Then, according to section \ref{subsec:Filtering}, several filtering limits can be given.
\begin{longtable}{lp{9.5cm}}
MINOBJECTS: & Minimum number of objects on one chip. If less, then a warning will appear.\\
 & Default value: 0\\
CUTS: & Gives the order and kind of filtering.\\
 & Default value: "RESMEAN"\\
LOWERCUTPERCENT: & Gives the percentage of objects not to be used in the lower range. A value of e.g. 0.1 corresponds to 10\% of objects in the lower range not being used.\\
 & Default value: 0.1\\
UPPERCUTPERCENT: & Gives the percentage of objects not to be used in the upper range. A value of e.g. 0.1 corresponds to 10\% of objects in the upper range not being used.\\
 & Default value: 0.1\\
LOWERCUTRESABS: & Gives the lower residual cut. For a value of e.g. -0.2 this means that all objects with a residual less than -0.2mag are not used.\\
 & Default value: -0.2\\
UPPERCUTRESABS: & Gives the upper residual cut. For a value of e.g. 0.2 this means that all objects with a residual larger than 0.2mag are not used.\\
 & Default value: 0.2\\
LOWERCUTMAG: & Gives the lower magnitude cut. For a value of e.g. 10 this means that all objects with a magnitude less than 10mag (meaning brighter) are not used.\\
 & Default value: 10\\
UPPERCUTMAG: & Gives the upper magnitude cut. For a value of e.g. 25 this means that all objects with a magnitude larger than 25mag (meaning fainter) are not used.\\
 & Default value: 25\\
SIGMAWIDTH: & Gives the width of sigma clipping. A value of 1 means that a 1$\sigma$-area around the mean is used.\\
 & Default value: 1\\
LOWERCUTRESMEAN: & Gives the lower magnitude cut w.r.t. the mean of the dataset. For a value of e.g -0.2 and a mean of 0.1(mag) this means that all objects with a residual smaller than -0.1mag are not used.\\
 & Default value: -0.2\\
UPPERCUTRESMEAN: & Gives the upper magnitude cut w.r.t. the mean of the dataset. For a value of e.g. 0.2 and a mean of 0.1(mag) this means that all objects with a residual larger than 0.3mag are not used.\\
 & Default value: 0.2\\
\caption{List of filtering arguments for main script}
\label{tab:FilteringArgumentsMainScript}
\end{longtable}

Furthermore several (sanity) checks are done in the beginning and during filtering. They cover all problems occurred during development but might not be complete!
\begin{itemize}
\item \textbf{Number of command line arguments:} In the current configuration, exactly eight arguments have to be given (cf. table \ref{tab:CommandLineArgumentsMainScript}). If more or less are given, the script ends with an error.
\item \textbf{Runmode:} As written in table \ref{tab:CommandLineArgumentsMainScript}, the script needs to know in which mode (RUN or NIGHT) the illumination correction has to be done. If this arguments does not match with one of the two just mentioned, the script will end with an error.
\item \textbf{Folder presence:} If an old illumination correction is detected, it is deleted with a warning message.
\item \textbf{Camera information:} It is checked if the \texttt{CHIPGEOMETRY} is set in the camera configuration file. From this several information are extracted: \texttt{ROWMAX} (the number of chips in x-direction), \texttt{COLUMNMAX} (the number of chips in y-direction), \texttt{PIXX} (the number of pixels in x-direction), \texttt{PIXY} (the number of pixels in y-direction), \texttt{PIXXMAX} (the maximum number of camera pixels in x-direction, calculated via $\texttt{ROWMAX} \cdot \texttt{PIXX}$) and \texttt{PIXYMAX} (the maximum number of camera pixels in y-direction, calculated via $\texttt{COLUMNMAX} \cdot \texttt{PIXY}$). If \texttt{CHIPGEOMETRY} is not set, the script ends with an error.
\item \textbf{Catalog presence:} Checks if there are LDAC catalogs available at all. These contain only those objects which were matched with the reference catalog. If not available, the script will end with an error.
\item \textbf{First filtering:} The first filtering keeps only objects with a magnitude less than 99mag and larger than -9999mag in all corresponding bands (observed filter and both color filters). Here, the convention is used that the magnitude of objects with no match in the reference catalog is set to 99mag. Furthermore the colorterm has to be larger than -10mag but smaller than 10mag. If after this step no objects are left, the script will end with an error.
\item \textbf{BADCCD flag filtering:} All objects which have the BADCCD flag set (BADCCD=1), e.g. due to a problematic chip, are sorted out. Afterwards it is checked if still enough objects are present. If not, the script will end with an error.
\item \textbf{Photometric calibration file presence:} If the zeropoint calibration file is missing (for the entire run in "RUNCALIB" mode or for one of the nights in "NIGHTCALIB" mode), the script ends with an error.
\item \textbf{Second filtering:} After filtering as described in section \ref{sec:Filtering}, the number of objects per chip is checked again with respect to "MINOBJECTS" as described in table \ref{tab:FilteringArgumentsMainScript}. If too few objects are left, the script will raise a warning, naming also the chip number.
\end{itemize}

After these pre-checks and filtering, the filtered LDAC catalog is used as input by the fitting algorithm (illum\_correction\_fit.py, written in Python). A detailed explanation can be found in section \ref{sec:IllumCorrectionFitting}.\\

After the fitting procedure, several values such as e.g. mean, variance and standard deviation are calculated. More information can be found in section \ref{sec:IllumCorrectionCalcsAfterFitting}.\\

Afterwards, several checkplots as described in section \ref{sec:IllumCorrectionCheckplots} and FITS correction files are created (illum\_correction\_contourplot\_fitfunction.py, written in Python).\\

All scripts are highly optimized and, where possible and reasonable, they also use multiprocessing features. E.g. filtering objects and creating statistics is done chip by chip (so they run in parallel), but the needed time is about a few seconds in total so with multiprocessing this step would not speed up significantly. As a counterexample, creating all checkplots in section \ref{sec:IllumCorrectionCheckplots} takes about six minutes with multiprocessing (splitting up each file on one processor calculating there subplot by subplot). Furthermore, all scripts are easily expandable for new features e.g. other filtering techniques or checkplots.


\subsection{Filtering}
\label{subsec:Filtering}
With given residuals, it is necessary to keep only objects within a certain range and to reject outliers. These can be caused by e.g. wrongly matched objects in the reference catalog and result in wrong magnitudes. For this purpose, the residual mean (equation \ref{eqn:mean}), variance (equation \ref{eqn:variance}) and standard deviation (equation \ref{eqn:sigma}) are calculated:
\begin{eqnarray}
\bar \epsilon & = & \frac{1}{n} \sum_{i=1}^{n} \epsilon_{i}\label{eqn:mean}\\
\mathrm{Var} & = & \frac{1}{n} \left(\sum_{i=1}^{n} \epsilon_{i}^{2} - \frac{\left( \sum_{i=1}^{n} \epsilon_{i} \right)^{2}}{n} \right) \label{eqn:variance}\\
\sigma & = & \sqrt{\mathrm{Var}}\label{eqn:sigma}
\end{eqnarray}

It is possible to choose between the following techniques or a sorted combination of them:

\begin{itemize}
\item Fixed residual limits: Fixed limits are a specific residual range, e.g. only objects with $-0.2\text{mag} < \epsilon < 0.2\text{mag}$ are kept. Asymmetric boundaries are also possible. Especially non-photometric nights can be excluded by this (keywords are LOWERCUTRESABS and UPPERCUTRESABS).
\item Residual limits w.r.t. the mean: These limits are a specific residual range which are calculated with respect to the mean, e.g. for a value of -0.2 and a mean of 0.1(mag) only objects with $-0.2\text{mag}+0.1\text{mag} < \epsilon < 0.2\text{mag}+0.1\text{mag}$, so $-0.1\text{mag} < \epsilon < 0.3\text{mag}$ are kept. Asymmetric boundaries are also possible. Especially non-photometric nights can be excluded by this (keywords are LOWERCUTRESMEAN and UPPERCUTRESMEAN).
\item Magnitude cut: An upper and lower magnitude cut can be given to exclude e.g. very faint and/or very bright objects. With this, only objects with a minimum and/or maximum S/N can be chosen (keywords are LOWERCUTMAG and UPPERCUTMAG).
\item Percentage: Only a fixed percentage of objects is kept, e.g. for a value of 0.2 the upper and lower 20\% are deleted. Again, asymmetric boundaries are possible (keywords are LOWERCUTPERCENT and UPPERCUTPERCENT).
\item Sigma clipping: Using the calculated standard deviation, only objects with a residuum smaller than this value with respect to the mean $\bar \epsilon$ are kept (keyword is SIGMAWIDTH).
\item Iterative sigma clipping: An iterative sigma clipping can be achieved via using the SIGMA argument several times. At the moment for all sigma clippings the same sigma width has to be used.
\end{itemize}

In some special cases, e.g. if one of the observations was taken during non-photometric conditions, there will be a lot of objects outside these ranges. Depending on the data, the illumination correction is also able to correct for this.\\
Also, it is very important how the cuts are chosen. The overall best solution for KiDS observations seems to be a residual cut of $\pm 0.2\text{mag}$ w.r.t. the mean (about 10\% of the stars are now marked as ``outliers"). For comparison, a 10\% cut (lower and upper) plus afterwards a 3$\sigma$ clipping is used in the estimation of the zeropoint. The reason for this is that in the latter case only the stars with precise magnitude measurements are kept to calculate a precise zeropoint. To get a usable illumination correction, not only these precise measurements are wanted, additionally also the magnitudes that are incorrect because of the non-uniform illumination of the camera are wanted. This means that the conditions for the ZP estimation are stricter than those for the illumination correction. In both cases non-photometric observations have to be excluded.
















\section{Fitting data}
\label{sec:IllumCorrectionFitting}
The needed command line arguments are:
\begin{table}[H]
\centering
\begin{tabular}{lp{11.5cm}}
-i: & Input file containing the data to be fitted.\\
-t: & LDAC table name containg all data\\
-p: & Output path where the file with the coefficients file shall be saved to.\\
\end{tabular}
\caption{List of command line arguments for fitting script}
\label{tab:CommandLineArgumentsFittingScript}
\end{table}

This script uses $\chi^2$-fit for fitting. As fitting function, 
\begin{eqnarray}
\epsilon = Ax^{2} + By^{2} + Cxy + Dx + Ey + F\left[chip\right]\label{eqn:residual}
\end{eqnarray}
is used, implemented in the code as
\begin{equation}
\epsilon = Ax^{2} + By^{2} + Cxy + Dx + Ey + \sum_{i=1}^{N} \delta_{iz}Fi .
\label{eqn:resprog}
\end{equation}
Here, x represents a NumPy array with all x-coordinates, y an array with all y-coordinates and z an array with the corresponding information on which chip the object is located. That means for a given x, y, z triple, that F will only count where i=z, e.g. for z=1 (object in on the first chip), equation \ref{eqn:resprog} reads as
\begin{eqnarray}
\epsilon & = & Ax^{2} + By^{2} + Cxy + Dx + Ey + \underbrace{\delta_{11}}_{=1} F1 + \underbrace{\delta_{21}}_{=0} F2 + \underbrace{\delta_{31}}_{=0} F3 + ...\\
 & = & Ax^{2} + By^{2} + Cxy + Dx + Ey + F1 .
\end{eqnarray}
Unfortunately, Python does not have an implemented $\delta$-function, so this had to be programmed by hand. This was done via the condition
\begin{eqnarray}
\mathrm{int}\left(i-z\right) == 0
\end{eqnarray}
As initial guess, all prefactors are set to 0.0 and all data points get an error calculated via Gaussian error propagation. At the moment the magnitude error of the observed objects and its counterpart from the reference catalog, the errors on the magnitude zeropoint, the extinction coefficient, the color term coefficient and color term are used. The error on the airmass is set to 0.0 because for this error no value is available or can be guessed.\\
Additionally, the center position of the illumination correction can be obtained by the derivative of equation \ref{eqn:residual} via
\begin{eqnarray}
\frac{\partial \epsilon}{\partial x}  \stackrel{!}= 0 = 2Ax + Cy + D\label{eqn:delx} \\
\frac{\partial \epsilon}{\partial y}  \stackrel{!}= 0 = 2By + Cx + E\label{eqn:dely}
\end{eqnarray}
Solving equation \ref{eqn:delx} for y and \ref{eqn:dely} for x:
\begin{eqnarray}
x = -\frac{2By + E}{C}\label{eqn:x}\\
y = -\frac{2Ax + D}{C}\label{eqn:y}
\end{eqnarray}
Inserting result \ref{eqn:y} into equation \ref{eqn:x} and this afterwards again into \ref{eqn:y} yields:
\begin{eqnarray}
x_{max} & = & \frac{CE-2BD}{4AB-C^{2}}\label{eqn:ResultX}\\
y_{max} & = & \frac{2AE-CD}{C^{2}-4AB}\label{eqn:ResultY} .
\end{eqnarray}



\section{Calculations after fitting}
\label{sec:IllumCorrectionCalcsAfterFitting}
The fitting results are first used to correct the data on catalog basis via
\begin{eqnarray}
m_{app,corr} = m_{app} - \epsilon
\end{eqnarray}
with $\epsilon$ defined as in equation \ref{eqn:residual}. Also the residuals after fitting, including errors (via Gaussian error propagation), are calculated accordingly.\\
Afterwards, several statistics of the residuals before and after fitting are calculated for each individual chip and for all chips combined:
\begin{itemize}
\item mean according to equation \ref{eqn:mean}
\item minimum
\item maximum
\item number of data points
\item variance according to equation \ref{eqn:variance}
\item standard deviation according to equation \ref{eqn:sigma}
\item number of objects that are compatible with 0 within a $1\sigma$-error
\item percent of objects that are compatible with 0 within a $1\sigma$-error (from 0 to 1)
\item center position of the illumination correction (maximum of the polynomial) according to equation \ref{eqn:ResultX} and \ref{eqn:ResultY} including errors.
\end{itemize}
The following values are calculated only for the entire camera for the ellipse:
\begin{itemize}
\item length of the minor axis
\item length of the major axis
\item ellipticity
\item numerical ellipticity
\item Rotation w.r.t. the y-axis, counted clock-wise (CW)
\item number of pixels that have a correction value between (at the moment) -0.015 and 0.0mag. These values are chosen such that in all illumination corrections, at least for KiDS observations, a certain number of pixels fulfil these requirements.
\item last value, given in percent (from 0 to 1).
\end{itemize}



\section{Checkplots}
\label{sec:IllumCorrectionCheckplots}
